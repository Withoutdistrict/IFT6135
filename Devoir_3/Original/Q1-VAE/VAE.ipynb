{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8y_h9goW_--j",
   "metadata": {
    "id": "8y_h9goW_--j"
   },
   "source": [
    "# IFT6135-A2022\n",
    "# Assignment 3: VAE Practical\n",
    "\n",
    "You must fill in your answers to various questions in this notebook, following which you must export this notebook to a Python file named `vae_solution.py` and submit it on Gradescope.\n",
    "\n",
    "Only edit the functions specified in the PDF (and wherever marked â€“ `# WRITE CODE HERE`). Do not change definitions or edit the rest of the template, else the autograder will not work.\n",
    "\n",
    "**Make sure you request a GPU runtime!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AdbBo0_tQp8y",
   "metadata": {
    "id": "AdbBo0_tQp8y"
   },
   "source": [
    "## VAE Basics\n",
    "\n",
    "Variational Autoencoders are generative latent-variable models that are popularly used for unsupervised learning and are aimed at maximizing the log-likelihood of the data, that is, maximizing $\\sum\\limits_{i=1}^N \\log p(x_i; \\theta)$ where $N$ is the number of data samples available. The generative story is as follows:\n",
    "\n",
    "\\begin{align*}\n",
    "  z &\\sim \\mathcal{N}(0, I) \\\\\n",
    "  x | z &\\sim \\mathcal{N}(\\mu_\\theta(z), \\Sigma_\\theta(z))\n",
    "\\end{align*}\n",
    "\n",
    "Given $\\mu_\\theta(\\cdot)$ and $\\Sigma_\\theta(\\cdot)$ are parameterized as arbitrary Neural Networks, one cannot obtain the log-likelihood $\\log \\mathbb{E}_{z}[p(x | z, \\theta)]$ in closed form and hence has to rely on variational assumptions for optimization.\n",
    "\n",
    "One way of optimizing for log-likelihood is to use the variational distribution $q_\\phi(z | x)$, which with a little bit of algebra leads to the ELBO, which is:\n",
    "\n",
    "\\begin{align*}\n",
    "  ELBO = \\sum_{i=1}^N \\left( \\mathbb{E}_{z\\sim q_\\phi(z|x_i)} [\\log p_\\theta(x_i | z)] + \\mathbb{KL}[q_\\phi(z|x_i) || \\mathcal{N}(0, I)] \\right)\n",
    "\\end{align*}\n",
    "\n",
    "This is the objective that we use for optimizing VAEs, where different flavours of VAE can be obtained by changing either the approximate posterior $q_\\phi$, the conditional likelihood distribution $p_\\theta$ or even the standard normal prior.\n",
    "\n",
    "The aim of this assignment would be to code a simple version of a VAE, where $q_\\phi(z|x)$ will be parameterized as $\\mathcal{N}(\\mu_\\phi(x), \\Sigma_\\phi(x))$ where $\\mu(x)$ is a mean vector and $\\Sigma(x)$ will be a **diagonal covariance matrix**, that is, it will only have non-zero entries on the diagonal.\n",
    "\n",
    "The likelihood $p_\\theta(x|z)$ will also be modeled as a Gaussian Distribution $\\mathcal{N}(\\mu_\\theta(z), I)$ where we parameterize the mean with another neural network but for simplicity, consider the identity covariance matrix.\n",
    "\n",
    "For details about VAEs, please refer to [Kingma's Paper](https://arxiv.org/abs/1312.6114) and the [Rezende's Paper](https://arxiv.org/abs/1401.4082)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f2d714",
   "metadata": {
    "id": "a1f2d714"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def fix_experiment_seed(seed=0):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed_all(seed)\n",
    "  torch.cuda.manual_seed(seed)\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "  torch.backends.cudnn.benchmark = False\n",
    "\n",
    "fix_experiment_seed()\n",
    "\n",
    "results_folder = Path(\"./results\")\n",
    "results_folder.mkdir(exist_ok = True)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78pkOxtP98fl",
   "metadata": {
    "id": "78pkOxtP98fl"
   },
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def show_image(image, nrow=8):\n",
    "  # Input: image\n",
    "  # Displays the image using matplotlib\n",
    "  grid_img = make_grid(image.detach().cpu(), nrow=nrow, padding=0)\n",
    "  plt.imshow(grid_img.permute(1, 2, 0))\n",
    "  plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bK_NDpHdO_fn",
   "metadata": {
    "id": "bK_NDpHdO_fn"
   },
   "source": [
    "## Set up the hyperparameters\n",
    "- Train Batch Size\n",
    "- Latent Dimensionality\n",
    "- Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5m7U3O5XC2i2",
   "metadata": {
    "id": "5m7U3O5XC2i2"
   },
   "outputs": [],
   "source": [
    "# Training Hyperparameters\n",
    "train_batch_size = 64   # Batch Size\n",
    "z_dim = 32        # Latent Dimensionality\n",
    "lr = 1e-4         # Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "X_BT47qn-GA-",
   "metadata": {
    "id": "X_BT47qn-GA-"
   },
   "source": [
    "## Set up dataset, we are using SVHN dataset for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3Gqto9rR-I3o",
   "metadata": {
    "id": "3Gqto9rR-I3o"
   },
   "outputs": [],
   "source": [
    "# Define Dataset Statistics\n",
    "image_size = 32\n",
    "input_channels = 3\n",
    "data_root = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lcwXsoUDEPwe",
   "metadata": {
    "id": "lcwXsoUDEPwe"
   },
   "outputs": [],
   "source": [
    "def get_dataloaders(data_root, batch_size):\n",
    "    normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                     std=[0.5, 0.5, 0.5])\n",
    "    transform = transforms.Compose((\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize))\n",
    "    \n",
    "    train = datasets.SVHN(data_root, split='train', download=True, transform=transform)\n",
    "    test = datasets.SVHN(data_root, split='test', download=True, transform=transform)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=batch_size)\n",
    "\n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HfRQis_EP-yh",
   "metadata": {
    "id": "HfRQis_EP-yh"
   },
   "source": [
    "## Visualize the Data\n",
    "\n",
    "Lets visualize what our data actually looks like! We are using the [SVHN dataset](http://ufldl.stanford.edu/housenumbers/) which comprises of images of house numbers seen from the streets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e8273b",
   "metadata": {
    "id": "52e8273b"
   },
   "outputs": [],
   "source": [
    "# Visualize the Dataset\n",
    "def visualize():\n",
    "  train_dataloader, _ = get_dataloaders(data_root=data_root, batch_size=train_batch_size)\n",
    "  imgs, labels = next(iter(train_dataloader))\n",
    "\n",
    "  save_image((imgs + 1.) * 0.5, './results/orig.png')\n",
    "  show_image((imgs + 1.) * 0.5)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PSzDGCJvQPvm",
   "metadata": {
    "id": "PSzDGCJvQPvm"
   },
   "source": [
    "## Define the Model Architectures\n",
    "\n",
    "For our VAE models, we use an encoder network and a decoder network, both of which have been pre-defined for ease of use in this assignment.\n",
    "\n",
    "Encoder: It is a model that maps input images to the latent space, and in particular, to the parameters of the distribution in the latent space.\n",
    "\n",
    "Decoder: It is a model that maps a sample in the latent space to a distribution in the observed space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812V5rIcHaaf",
   "metadata": {
    "id": "812V5rIcHaaf"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "  def __init__(self, nc, nef, nz, isize, device):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    # Device\n",
    "    self.device = device\n",
    "\n",
    "    # Encoder: (nc, isize, isize) -> (nef*8, isize//16, isize//16)\n",
    "    self.encoder = nn.Sequential(\n",
    "      nn.Conv2d(nc, nef, 4, 2, padding=1),\n",
    "      nn.LeakyReLU(0.2, True),\n",
    "      nn.BatchNorm2d(nef),\n",
    "\n",
    "      nn.Conv2d(nef, nef * 2, 4, 2, padding=1),\n",
    "      nn.LeakyReLU(0.2, True),\n",
    "      nn.BatchNorm2d(nef * 2),\n",
    "\n",
    "      nn.Conv2d(nef * 2, nef * 4, 4, 2, padding=1),\n",
    "      nn.LeakyReLU(0.2, True),\n",
    "      nn.BatchNorm2d(nef * 4),\n",
    "\n",
    "      nn.Conv2d(nef * 4, nef * 8, 4, 2, padding=1),\n",
    "      nn.LeakyReLU(0.2, True),\n",
    "      nn.BatchNorm2d(nef * 8),\n",
    "    )\n",
    "\n",
    "  def forward(self, inputs):\n",
    "    batch_size = inputs.size(0)\n",
    "    hidden = self.encoder(inputs)\n",
    "    hidden = hidden.view(batch_size, -1)\n",
    "    return hidden\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "  def __init__(self, nc, ndf, nz, isize):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    # Map the latent vector to the feature map space\n",
    "    self.ndf = ndf\n",
    "    self.out_size = isize // 16\n",
    "    self.decoder_dense = nn.Sequential(\n",
    "      nn.Linear(nz, ndf * 8 * self.out_size * self.out_size),\n",
    "      nn.ReLU(True)\n",
    "    )\n",
    "\n",
    "    self.decoder_conv = nn.Sequential(\n",
    "      nn.UpsamplingNearest2d(scale_factor=2),\n",
    "      nn.Conv2d(ndf * 8, ndf * 4, 3, 1, padding=1),\n",
    "      nn.LeakyReLU(0.2, True),\n",
    "\n",
    "      nn.UpsamplingNearest2d(scale_factor=2),\n",
    "      nn.Conv2d(ndf * 4, ndf * 2, 3, 1, padding=1),\n",
    "      nn.LeakyReLU(0.2, True),\n",
    "\n",
    "      nn.UpsamplingNearest2d(scale_factor=2),\n",
    "      nn.Conv2d(ndf * 2, ndf, 3, 1, padding=1),\n",
    "      nn.LeakyReLU(0.2, True),\n",
    "\n",
    "      nn.UpsamplingNearest2d(scale_factor=2),\n",
    "      nn.Conv2d(ndf, nc, 3, 1, padding=1)\n",
    "    )\n",
    "\n",
    "  def forward(self, input):\n",
    "    batch_size = input.size(0)\n",
    "    hidden = self.decoder_dense(input).view(\n",
    "      batch_size, self.ndf * 8, self.out_size, self.out_size)\n",
    "    output = self.decoder_conv(hidden)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ai9uhzVM1P2",
   "metadata": {
    "id": "3ai9uhzVM1P2"
   },
   "source": [
    "# Diagonal Gaussian Distribution\n",
    "\n",
    "The following class provides a way of setting up the diagonal gaussian distribution, which is parameterized by a mean vector, and a logvar vector of the same shape as the mean vector. The logvar vector denotes the log of the variances on the diagonals of a diagonal covariance matrix.\n",
    "\n",
    "The task is to implement the following functions:\n",
    "\n",
    "- Sampling: Provide the methodology of computing a **reparamterized** sample from the given distribution.\n",
    "- KL Divergence: Compute and return the KL divergence of the distribution with the standard normal, that is, $\\mathbb{KL}[\\mathcal{N}(\\mu, \\Sigma) || \\mathcal{N}(0, I)]$ where $\\Sigma$ is a diagonal covariance matrix.\n",
    "- Negative Log Likelihood: Given some data $x$, returns the log likelihood under the current gaussian, that is, $\\log \\mathcal{N}(x | \\mu, \\Sigma)$\n",
    "- Mode: Returns the mode of the distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yvUO-v2bG_Tq",
   "metadata": {
    "id": "yvUO-v2bG_Tq"
   },
   "outputs": [],
   "source": [
    "class DiagonalGaussianDistribution(object):\n",
    "  # Gaussian Distribution with diagonal covariance matrix\n",
    "  def __init__(self, mean, logvar=None):\n",
    "    super(DiagonalGaussianDistribution, self).__init__()\n",
    "    # Parameters:\n",
    "    # mean: A tensor representing the mean of the distribution\n",
    "    # logvar: Optional tensor representing the log of the standard variance\n",
    "    #         for each of the dimensions of the distribution \n",
    "\n",
    "    self.mean = mean\n",
    "    if logvar is None:\n",
    "        logvar = torch.zeros_like(self.mean)\n",
    "    self.logvar = torch.clamp(logvar, -30., 20.)\n",
    "\n",
    "    self.std = torch.exp(0.5 * self.logvar)\n",
    "    self.var = torch.exp(self.logvar)\n",
    "\n",
    "  def sample(self):\n",
    "    # Provide a reparameterized sample from the distribution\n",
    "    # Return: Tensor of the same size as the mean\n",
    "    sample = None       # WRITE CODE HERE\n",
    "    return sample\n",
    "\n",
    "  def kl(self):\n",
    "    # Compute the KL-Divergence between the distribution with the standard normal N(0, I)\n",
    "    # Return: Tensor of size (batch size,) containing the KL-Divergence for each element in the batch\n",
    "    kl_div = None       # WRITE CODE HERE\n",
    "    return kl_div\n",
    "\n",
    "  def nll(self, sample, dims=[1, 2, 3]):\n",
    "    # Computes the negative log likelihood of the sample under the given distribution\n",
    "    # Return: Tensor of size (batch size,) containing the log-likelihood for each element in the batch\n",
    "    negative_ll = None    # WRITE CODE HERE\n",
    "    return negative_ll\n",
    "\n",
    "  def mode(self):\n",
    "    # Returns the mode of the distribution\n",
    "    mode = None     # WRITE CODE HERE\n",
    "    return mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddcmfrhM6kQ",
   "metadata": {
    "id": "1ddcmfrhM6kQ"
   },
   "source": [
    "# VAE Model\n",
    "\n",
    "The Variational Autoencoder (VAE) model consists of an encoder network that parameterizes the distribution $q_\\phi$ as a Diagonal Gaussian Distribution through the (mean, log variance) parameterization and a decoder network that parameterizes the distribution $p_\\theta$ as another Diagonal Gaussian Distribution with an identity covariance matrix.\n",
    "\n",
    "The task is to implement the following\n",
    "\n",
    "- Encode: The function that takes as input a batched data sample, and returns the approximate posterior distribution $q_\\phi$\n",
    "- Decode: The function that takes as input a batched sample from the latent space, and returns the mode of the distribution $p_\\theta$\n",
    "- Sample: Generates a novel sample by sampling from the prior and then using the mode of the distribution $p_\\theta$\n",
    "- Forward: The main function for training. Given a data sample x, encode it using the encode function, and then obtain a reparameterized sample from it, and finally decode it. Return the mode from the decoded distribution $p_\\theta$, as well as the conditional likelihood and KL terms of the loss. Note that the loss terms should be of size (batch size,) as the averaging is taken care of in the training loop\n",
    "- Log Likelihood: The main function for testing that approximates the log-likelihood of the given data. It is computed using importance sampling as $\\log \\frac{1}{K} \\sum\\limits_{k=1}^K \\frac{p_\\theta(x, z_k)}{q_\\phi(z_k|x)}$ where $z_k \\sim q_\\phi(z | x)$. Please compute this quantity using the log-sum-exp trick for more stable computations; you can use PyTorch's logsumexp() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "m178l8OJ0_qp",
   "metadata": {
    "id": "m178l8OJ0_qp"
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "  def __init__(self, in_channels=3, decoder_features=32, encoder_features=32, z_dim=100, input_size=32, device=torch.device(\"cuda:0\")):\n",
    "    super(VAE, self).__init__()\n",
    "\n",
    "    self.z_dim = z_dim\n",
    "    self.in_channels = in_channels\n",
    "    self.device = device\n",
    "\n",
    "    # Encode the Input\n",
    "    self.encoder = Encoder(nc=in_channels, \n",
    "                            nef=encoder_features, \n",
    "                            nz=z_dim, \n",
    "                            isize=input_size, \n",
    "                            device=device\n",
    "                            )\n",
    "\n",
    "    # Map the encoded feature map to the latent vector of mean, (log)variance\n",
    "    out_size = input_size // 16\n",
    "    self.mean = nn.Linear(encoder_features * 8 * out_size * out_size, z_dim)\n",
    "    self.logvar = nn.Linear(encoder_features * 8 * out_size * out_size, z_dim)\n",
    "\n",
    "    # Decode the Latent Representation\n",
    "    self.decoder = Decoder(nc=in_channels, \n",
    "                           ndf=decoder_features, \n",
    "                           nz=z_dim, \n",
    "                           isize=input_size\n",
    "                           )\n",
    "\n",
    "  def encode(self, x):\n",
    "    # Input:\n",
    "    #   x: Tensor of shape (batch_size, 3, 32, 32)\n",
    "    # Returns:\n",
    "    #   posterior: The posterior distribution q_\\phi(z | x)\n",
    "\n",
    "    # WRITE CODE HERE\n",
    "    pass\n",
    "\n",
    "  def decode(self, z):\n",
    "    # Input:\n",
    "    #   z: Tensor of shape (batch_size, z_dim)\n",
    "    # Returns\n",
    "    #   conditional distribution: The likelihood distribution p_\\theta(x | z)\n",
    "    \n",
    "    # WRITE CODE HERE\n",
    "\n",
    "    pass\n",
    "\n",
    "  def sample(self, batch_size):\n",
    "    # Input:\n",
    "    #   batch_size: The number of samples to generate\n",
    "    # Returns:\n",
    "    #   samples: Generated samples using the decoder\n",
    "    #            Size: (batch_size, 3, 32, 32)\n",
    "\n",
    "    # WRITE CODE HERE\n",
    "\n",
    "    pass\n",
    "\n",
    "  def log_likelihood(self, x, K=100):\n",
    "    # Approximate the log-likelihood of the data using Importance Sampling\n",
    "    # Inputs:\n",
    "    #   x: Data sample tensor of shape (batch_size, 3, 32, 32)\n",
    "    #   K: Number of samples to use to approximate p_\\theta(x)\n",
    "    # Returns:\n",
    "    #   ll: Log likelihood of the sample x in the VAE model using K samples\n",
    "    #       Size: (batch_size,)\n",
    "    posterior = self.encode(x)\n",
    "    prior = DiagonalGaussianDistribution(torch.zeros_like(posterior.mean))\n",
    "\n",
    "    log_likelihood = torch.zeros(x.shape[0], K).to(self.device)\n",
    "    for i in range(K):\n",
    "      z = None                        # WRITE CODE HERE (sample from q_phi)\n",
    "      recon = None                    # WRITE CODE HERE (decode to conditional distribution)\n",
    "      log_likelihood[:, i] = None     # WRITE CODE HERE (log of the summation terms in approximate log-likelihood, that is, log p_\\theta(x, z_i) - log q_\\phi(z_i | x))\n",
    "      del z, recon\n",
    "    \n",
    "    ll = None     # WRITE CODE HERE (compute the final log-likelihood using the log-sum-exp trick)\n",
    "    return ll\n",
    "\n",
    "  def forward(self, x):\n",
    "    # Input:\n",
    "    #   x: Tensor of shape (batch_size, 3, 32, 32)\n",
    "    # Returns:\n",
    "    #   reconstruction: The mode of the distribution p_\\theta(x | z) as a candidate reconstruction\n",
    "    #                   Size: (batch_size, 3, 32, 32)\n",
    "    #   Conditional Negative Log-Likelihood: The negative log-likelihood of the input x under the distribution p_\\theta(x | z)\n",
    "    #                                         Size: (batch_size,)\n",
    "    #   KL: The KL Divergence between the variational approximate posterior with N(0, I)\n",
    "    #       Size: (batch_size,)\n",
    "    posterior = None    # WRITE CODE HERE\n",
    "    latent_z = None     # WRITE CODE HERE (sample a z)\n",
    "    recon = None        # WRITE CODE HERE (decode)\n",
    "\n",
    "    return recon.mode(), recon.nll(x), posterior.kl()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2TprgdjZvoKm",
   "metadata": {
    "id": "2TprgdjZvoKm"
   },
   "source": [
    "Here we define the model as well as the optimizer to take care of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5126e21",
   "metadata": {
    "id": "a5126e21"
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "  model = VAE(in_channels=input_channels, \n",
    "            input_size=image_size, \n",
    "            z_dim=z_dim, \n",
    "            decoder_features=32, \n",
    "            encoder_features=32, \n",
    "            device=device\n",
    "            )\n",
    "  model.to(device)\n",
    "  optimizer = Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7444b0b",
   "metadata": {
    "id": "f7444b0b"
   },
   "source": [
    "Finally, let's start training!\n",
    "Visualization of the samples generated, the original dataset and the reconstructions are saved locally in the notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b12ed1",
   "metadata": {
    "id": "92b12ed1"
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  train_dataloader, _ = get_dataloaders(data_root, batch_size=train_batch_size)\n",
    "  for epoch in range(epochs):\n",
    "    with tqdm(train_dataloader, unit=\"batch\", leave=False) as tepoch:\n",
    "      model.train()\n",
    "      for batch in tepoch:\n",
    "        tepoch.set_description(f\"Epoch: {epoch}\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        imgs, _ = batch\n",
    "        batch_size = imgs.shape[0]\n",
    "        x = imgs.to(device)\n",
    "\n",
    "        recon, nll, kl = model(x)\n",
    "        loss = (nll + kl).mean()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        tepoch.set_postfix(loss=loss.item())\n",
    "\n",
    "    samples = model.sample(batch_size=64)\n",
    "    save_image((x + 1.) * 0.5, './results/orig.png')\n",
    "    save_image((recon + 1.) * 0.5, './results/recon.png')\n",
    "    save_image((samples + 1.) * 0.5, f'./results/samples_{epoch}.png')\n",
    "\n",
    "  show_image(((samples + 1.) * 0.5).clamp(0., 1.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "itBFbLeA-i2s",
   "metadata": {
    "id": "itBFbLeA-i2s"
   },
   "source": [
    "Once the training of the model is done, we can use the model to approximate the log-likelihood of the test data using the function that we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "T1kDN7e366tA",
   "metadata": {
    "id": "T1kDN7e366tA"
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "  _, test_dataloader = get_dataloaders(data_root, batch_size=train_batch_size)\n",
    "  with torch.no_grad():\n",
    "    with tqdm(test_dataloader, unit=\"batch\", leave=True) as tepoch:\n",
    "      model.eval()\n",
    "      log_likelihood = 0.\n",
    "      num_samples = 0.\n",
    "      for batch in tepoch:\n",
    "        tepoch.set_description(f\"Epoch: {epoch}\")\n",
    "        imgs,_ = batch\n",
    "        batch_size = imgs.shape[0]\n",
    "        x = imgs.to(device)\n",
    "\n",
    "        log_likelihood += model.log_likelihood(x).sum()\n",
    "        num_samples += batch_size\n",
    "        tepoch.set_postfix(log_likelihood=log_likelihood / num_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3PW1Xgz6-rbp",
   "metadata": {
    "id": "3PW1Xgz6-rbp"
   },
   "source": [
    "Finally, we also visualize the interpolation between two points in the latent space: $z_1$ and $z_2$ by choosing points at equal intervals on the line from the two points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-b47g2Bj7IF-",
   "metadata": {
    "id": "-b47g2Bj7IF-"
   },
   "outputs": [],
   "source": [
    "def interpolate(model, z_1, z_2, n_samples):\n",
    "  # Interpolate between z_1 and z_2 with n_samples number of points, with the first point being z_1 and last being z_2.\n",
    "  # Inputs:\n",
    "  #   z_1: The first point in the latent space\n",
    "  #   z_2: The second point in the latent space\n",
    "  #   n_samples: Number of points interpolated\n",
    "  # Returns:\n",
    "  #   sample: The mode of the distribution obtained by decoding each point in the latent space\n",
    "  #           Should be of size (n_samples, 3, 32, 32)\n",
    "  lengths = torch.linspace(0., 1., n_samples).unsqueeze(1).to(device)\n",
    "  z = None    # WRITE CODE HERE (interpolate z_1 to z_2 with n_samples points)\n",
    "  return model.decode(z).mode()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  z_1 = torch.randn(1, z_dim).to(device)\n",
    "  z_2 = torch.randn(1, z_dim).to(device)\n",
    "\n",
    "  interp = interpolate(model, z_1, z_2, 10)\n",
    "  show_image((interp + 1.) * 0.5, nrow=10)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
